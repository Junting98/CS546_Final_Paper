In this paper, we propose a meta-learning based framework that could help address the common issues encountered in continual event detection, i.e. high cost for retrain and catastrophic forgetting, and our base model significantly outperforms the classical method of finetune+pretrain. Also, our proposed mode-agnostic representation modules could be easily integrated to other methods and adapted to other continual information extraction tasks. We found that our model is quite sensitive to hyper-parameters, i.e. learning rate and hidden size in Adaption Module; however, we did not run a concrete search of hyper-parameters due to the limitation of computation resources. Some future works could focus on the tuning of our proposed model. In addition, we could implement  the combination of our method with \cite{yu2021lifelong}  to see how much knowledge distillation and knowledge transfer would help improve our method. We could also run experiments on more data to get a more concrete conclusion.